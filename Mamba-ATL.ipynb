{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d764ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os,json\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from operator import truediv\n",
    "import spectral\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import (IncrementalPCA, PCA)\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             cohen_kappa_score, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import cdist\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import legacy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afcec010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadHSIData(method):\n",
    "    data_path = os.path.join(os.getcwd(),'../HSI/')\n",
    "    if method == 'SA':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "        Num_Classes = 16\n",
    "        target_names = ['Weeds_1','Weeds_2','Fallow',\n",
    "                        'Fallow_rough_plow','Fallow_smooth', 'Stubble','Celery',\n",
    "                        'Grapes_untrained','Soil_vinyard_develop','Corn_Weeds',\n",
    "                        'Lettuce_4wk','Lettuce_5wk','Lettuce_6wk',\n",
    "                        'Lettuce_7wk', 'Vinyard_untrained','Vinyard_trellis']\n",
    "    elif method == 'PU':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "        Num_Classes = 9\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted','Soil','Bitumen',\n",
    "                        'Bricks','Shadows']\n",
    "    elif method == 'UH':\n",
    "      HSI = sio.loadmat(os.path.join(data_path, 'HU.mat'))['HSI']\n",
    "      GT = sio.loadmat(os.path.join(data_path, 'HU_gt.mat'))['gt']\n",
    "      Num_Classes = 15\n",
    "      target_names = ['Healthy grass', 'Stressed grass', 'Synthetic grass', 'Trees',\n",
    "                    'Soil', 'Water', 'Residential', 'Commercial', 'Road',\n",
    "                    'Highway', 'Railway', 'Parking Lot 1', 'Parking Lot 2',\n",
    "                    'Tennis Court', 'Running Track']\n",
    "    return HSI, GT, Num_Classes, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c80b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLMethod(method, HSI, NC = 75):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    if method == 'PCA': ## PCA\n",
    "        pca = PCA(n_components = NC, whiten = True)\n",
    "        RHSI = pca.fit_transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'iPCA': ## Incremental PCA\n",
    "        n_batches = 256\n",
    "        inc_pca = IncrementalPCA(n_components = NC)\n",
    "        for X_batch in np.array_split(RHSI, n_batches):\n",
    "          inc_pca.partial_fit(X_batch)\n",
    "        X_ipca = inc_pca.transform(RHSI)\n",
    "        RHSI = np.reshape(X_ipca, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "369dc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrTeSplit(HSI, GT, trRatio, vrRatio, teRatio, randomState=345):\n",
    "    Tr, Te, TrC, TeC = train_test_split(HSI, GT, test_size=teRatio,\n",
    "                                        random_state=randomState, stratify=GT)\n",
    "    totalTrRatio = trRatio + vrRatio\n",
    "    new_vrRatio = vrRatio / totalTrRatio\n",
    "    Tr, Va, TrC, VaC = train_test_split(Tr, TrC, test_size=new_vrRatio,\n",
    "                                        random_state=randomState, stratify=TrC)\n",
    "    return Tr, Va, Te, TrC, VaC, TeC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae41f5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhongruima/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "HSID = \"PU\"\n",
    "DLM = \"PCA\"\n",
    "WS = 8\n",
    "teRatio = 0.50\n",
    "vrRatio = 0.90\n",
    "trRatio = 0.10\n",
    "k = 15\n",
    "adam = tf.keras.optimizers.legacy.Adam(lr = 0.001, decay = 1e-06)\n",
    "epochs = 5\n",
    "batch_size = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f25f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageCubes(HSI, GT, WS=WS, removeZeroLabels=True):\n",
    "    num_rows, num_cols, num_bands = HSI.shape\n",
    "    margin = int(WS / 2)\n",
    "    padded_data = np.pad(HSI, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    image_cubes = np.zeros((num_rows * num_cols, WS, WS, num_bands))\n",
    "    patchesLabels = np.zeros((num_rows * num_cols))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, num_rows + margin):\n",
    "        for c in range(margin, num_cols + margin):\n",
    "            cube = padded_data[r - margin: r + margin, c - margin: c + margin, :]\n",
    "            image_cubes[patchIndex, :, :, :] = cube\n",
    "            patchesLabels[patchIndex] = GT[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "      image_cubes = image_cubes[patchesLabels>0,:,:,:]\n",
    "      patchesLabels = patchesLabels[patchesLabels>0]\n",
    "      patchesLabels -= 1\n",
    "    return image_cubes, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90bb055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationReports(TeC, Te_Pred, target_names):\n",
    "    classification = classification_report(np.argmax(TeC, axis=1), np.argmax(Te_Pred, axis=1), target_names = target_names)\n",
    "    oa = accuracy_score(np.argmax(TeC, axis=1), np.argmax(Te_Pred, axis=1))\n",
    "    confusion = confusion_matrix(np.argmax(TeC, axis=1), np.argmax(Te_Pred, axis=1))\n",
    "    list_diag = np.diag(confusion)\n",
    "    list_raw_sum = np.sum(confusion, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    aa = np.mean(each_acc)\n",
    "    kappa = cohen_kappa_score(np.argmax(TeC, axis=1), np.argmax(Te_Pred, axis=1))\n",
    "    return classification, confusion, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f037c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSVResults(file_name, classification, confusion, Parameters,\n",
    "                Flops, Tr_Time, Te_Time, DL_Time, kappa, oa, aa, each_acc):\n",
    "    classification = str(classification)\n",
    "    confusion = str(confusion)\n",
    "    with open(file_name, 'w') as CSV_file:\n",
    "      CSV_file.write('{} Tr_Time'.format(Tr_Time))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Te_Time'.format(Te_Time))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} DL_Time'.format(DL_Time))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Flops'.format(Flops))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Parameters'.format(Parameters))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Average accuracy (%)'.format(aa))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{}'.format(classification))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{}'.format(each_acc))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{}'.format(confusion))\n",
    "    return CSV_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a93f7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Ground Truths\n",
    "def GT_Plot(CRDHSI, GT, model, WS, k):\n",
    "  Predicted = model.predict(CRDHSI)\n",
    "  Predicted = np.argmax(Predicted, axis=1)\n",
    "  height, width = np.shape(GT)\n",
    "  ## Calculate the predicted Ground Truths\n",
    "  outputs = np.zeros((height, width))\n",
    "  count = 0\n",
    "  for AA in range(height):\n",
    "    for BB in range(width):\n",
    "      target = int(GT[AA,BB])\n",
    "      if target == 0:\n",
    "        continue\n",
    "      else:\n",
    "        outputs[AA][BB] = Predicted[count]\n",
    "        count = count+1\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd670082",
   "metadata": {},
   "outputs": [],
   "source": [
    "HSI, GT, Num_Classes, target_names = LoadHSIData(HSID)\n",
    "start = time.time()\n",
    "RDHSI = DLMethod(DLM, HSI, NC = k)\n",
    "end = time.time()\n",
    "DL_Time = end - start\n",
    "CRDHSI, CGT = ImageCubes(RDHSI, GT, WS = WS)\n",
    "Tr, Va, Te, TrC, VaC, TeC = TrTeSplit(CRDHSI, CGT, trRatio, vrRatio, teRatio)\n",
    "TrC = to_categorical(TrC)\n",
    "VaC = to_categorical(VaC)\n",
    "TeC = to_categorical(TeC)\n",
    "CHSI = to_categorical(CGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88babd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Flops\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "    def _freeze_to_graph_def(concrete_fn):\n",
    "        frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_fn)\n",
    "        return graph_def\n",
    "except Exception:\n",
    "    from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "    def _freeze_to_graph_def(concrete_fn):\n",
    "        frozen_func = convert_variables_to_constants_v2(concrete_fn)\n",
    "        return frozen_func.graph.as_graph_def(add_shapes=True)\n",
    "\n",
    "def compute_flops(model, sample_input, training=False, return_macs=False):\n",
    "    # 1) 先跑一遍，确保所有“用得到”的层都被 build\n",
    "    _ = model(sample_input, training=training)\n",
    "\n",
    "    # 2) 包成 tf.function 并具体化\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def _wrapped(x):\n",
    "        return model(x, training=training)\n",
    "    concrete = _wrapped.get_concrete_function(\n",
    "        tf.TensorSpec(sample_input.shape, dtype=sample_input.dtype)\n",
    "    )\n",
    "\n",
    "    # 3) 冻结为静态图\n",
    "    graph_def = _freeze_to_graph_def(concrete)\n",
    "\n",
    "    # 4) 用 v1 profiler 统计 total_float_ops（FLOPs）\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "\n",
    "    total_flops = int(flops.total_float_ops) if flops is not None else 0\n",
    "    return total_flops // 2 if return_macs else total_flops  # return_macs=True 时给 MACs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa72ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count samples per class\n",
    "def count_class_samples(labels, num_classes):\n",
    "    class_counts = {f\"class_{i}\": 0 for i in range(num_classes)}\n",
    "    for label in labels:\n",
    "        class_index = np.argmax(label)\n",
    "        class_counts[f\"class_{class_index}\"] += 1\n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralSpatialTokenGeneration(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels, **kwargs):\n",
    "        super(SpectralSpatialTokenGeneration, self).__init__(**kwargs)\n",
    "        self.spatial_tokens = Dense(out_channels)\n",
    "        self.spectral_tokens = Dense(out_channels)\n",
    "    def call(self, x):\n",
    "        # x: (B, H, W, C)\n",
    "        B = tf.shape(x)[0]\n",
    "        H = tf.shape(x)[1]\n",
    "        W = tf.shape(x)[2]\n",
    "        C = tf.shape(x)[3]\n",
    "\n",
    "        # 你的原始实现等价于把图像展平到 L = H*W，再做 Dense\n",
    "        L = H * W\n",
    "        flat = tf.reshape(x, [B, L, C])              # (B, L, C)\n",
    "\n",
    "        spatial_tokens  = self.spatial_tokens(flat)  # (B, L, out_channels)\n",
    "        spectral_tokens = self.spectral_tokens(flat) # (B, L, out_channels)\n",
    "        return spatial_tokens, spectral_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18121362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.all_head_size = self.num_heads * self.head_dim\n",
    "        self.query = Dense(self.all_head_size)\n",
    "        self.key = Dense(self.all_head_size)\n",
    "        self.value = Dense(self.all_head_size)\n",
    "        self.dropout = Dropout(dropout)\n",
    "    def call(self, query, key, value):\n",
    "        # query/key/value: (B, L, E)\n",
    "        B = tf.shape(query)[0]\n",
    "        L = tf.shape(query)[1]\n",
    "\n",
    "        q = self.query(query)   # (B, L, all_head)\n",
    "        k = self.key(key)\n",
    "        v = self.value(value)\n",
    "\n",
    "        def split_heads(t):\n",
    "            t = tf.reshape(t, [B, L, self.num_heads, self.head_dim])  # (B, L, H, D)\n",
    "            return tf.transpose(t, [0, 2, 1, 3])                      # (B, H, L, D)\n",
    "\n",
    "        q = split_heads(q)\n",
    "        k = split_heads(k)\n",
    "        v = split_heads(v)\n",
    "\n",
    "        # 注意力分数\n",
    "        scale = tf.math.sqrt(tf.cast(self.head_dim, tf.float32))\n",
    "        scores = tf.matmul(q, k, transpose_b=True) / scale            # (B, H, L, L)\n",
    "        weights = tf.nn.softmax(scores, axis=-1)                      # (B, H, L, L)\n",
    "\n",
    "        attn = tf.matmul(weights, v)                                  # (B, H, L, D)\n",
    "        attn = tf.transpose(attn, [0, 2, 1, 3])                       # (B, L, H, D)\n",
    "        attn = tf.reshape(attn, [B, L, self.all_head_size])           # (B, L, E)\n",
    "        attn = self.dropout(attn)\n",
    "        return attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe29f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralSpatialFeatureEnhancement(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels, **kwargs):\n",
    "        super(SpectralSpatialFeatureEnhancement, self).__init__(**kwargs)\n",
    "        self.spatial_gate = Sequential([\n",
    "            Dense(out_channels),\n",
    "            Activation('sigmoid'),\n",
    "            Reshape((1, out_channels))\n",
    "        ])\n",
    "        self.spectral_gate = Sequential([\n",
    "            Dense(out_channels),\n",
    "            Activation('sigmoid'),\n",
    "            Reshape((1, out_channels))\n",
    "        ])\n",
    "    def call(self, spatial_tokens, spectral_tokens, center_tokens):\n",
    "        spatial_enhanced = spatial_tokens * self.spatial_gate(center_tokens)\n",
    "        spectral_enhanced = spectral_tokens * self.spectral_gate(center_tokens)\n",
    "        return spatial_enhanced, spectral_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SSMCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_dim = state_dim\n",
    "        self.state_transition = Dense(state_dim)\n",
    "        self.state_update     = Dense(state_dim)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self.state_dim\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        # inputs: (B, E), states[0]: (B, state_dim)\n",
    "        prev_state = states[0]\n",
    "        new_state = self.state_transition(prev_state) + self.state_update(inputs)\n",
    "        return new_state, [new_state]\n",
    "    \n",
    "class StateSpaceModel(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim, **kwargs):\n",
    "        super(StateSpaceModel, self).__init__(**kwargs)\n",
    "        self.rnn = tf.keras.layers.RNN(_SSMCell(state_dim),\n",
    "                                       return_sequences=False,\n",
    "                                       return_state=False)\n",
    "    def call(self, x):\n",
    "        return self.rnn(x)   # (B, state_dim)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22e00248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSMambaModel(tf.keras.Model):\n",
    "    def __init__(self, out_channels, num_heads, state_dim, dropout=0.1, **kwargs):\n",
    "        super(SSMambaModel, self).__init__(**kwargs)\n",
    "        self.token_generation = SpectralSpatialTokenGeneration(out_channels)\n",
    "        self.multi_head_attention = MultiHeadAttention(out_channels, num_heads, dropout)\n",
    "        self.feature_enhancement = SpectralSpatialFeatureEnhancement(out_channels)\n",
    "        self.state_space_model = StateSpaceModel(state_dim)\n",
    "        self.dense = Dense(units=128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        self.dropout = Dropout(0.4)\n",
    "        self.classifier = Dense(Num_Classes, activation='softmax')\n",
    "    def set_num_classes(self, n):\n",
    "        self.num_classes = int(n)\n",
    "        self.classifier = Dense(self.num_classes, activation='softmax')\n",
    "    def call(self, x):\n",
    "        spatial_tokens, spectral_tokens = self.token_generation(x)\n",
    "        center_tokens = spatial_tokens[:, x.shape[1] // 2, :]\n",
    "        spatial_enhanced, spectral_enhanced = self.feature_enhancement(spatial_tokens, spectral_tokens, center_tokens)\n",
    "        attention_output = self.multi_head_attention(spatial_enhanced, spectral_enhanced, spectral_enhanced)\n",
    "        state_output = self.state_space_model(attention_output)\n",
    "        output = self.classifier(state_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f744681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty Sampling\n",
    "def uncertainty_sampling(model, X_pool, query_size):\n",
    "    probs = model.predict(X_pool)\n",
    "    uncertainty = -np.max(probs, axis=1)  # Lower max prob indicates higher uncertainty\n",
    "    query_indices = np.argsort(uncertainty)[-query_size:]  # Get indices of most uncertain samples\n",
    "    return query_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25fcfd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diversity Sampling \n",
    "def diversity_sampling(X_pool, query_size):\n",
    "    num_samples, H, W, C = X_pool.shape\n",
    "    query_indices = []\n",
    "    neighborhood_size=3\n",
    "    half_size = neighborhood_size // 2\n",
    "    for i in range(num_samples):\n",
    "        current_sample = X_pool[i]\n",
    "        diversity_values = np.zeros((H, W))\n",
    "        for h in range(half_size, H - half_size):\n",
    "            for w in range(half_size, W - half_size):\n",
    "                neighborhood = current_sample[h - half_size:h + half_size + 1, w - half_size:w + half_size + 1, :]\n",
    "                reshaped_neighborhood = neighborhood.reshape(-1, C)\n",
    "                distances = cdist(reshaped_neighborhood, reshaped_neighborhood, metric='euclidean')\n",
    "                diversity_metric = np.mean(distances)\n",
    "                diversity_values[h, w] = diversity_metric\n",
    "        flat_diversity_values = diversity_values.flatten()\n",
    "        query_indices = np.argsort(flat_diversity_values)[-query_size:]\n",
    "    return query_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c44bcb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Query\n",
    "def hybrid_query_strategy(model, X_pool, query_size):\n",
    "    uncertainty_indices = uncertainty_sampling(model, X_pool, query_size)\n",
    "    diversity_indices = diversity_sampling(X_pool, query_size)\n",
    "    query_indices = np.unique(np.concatenate((uncertainty_indices, diversity_indices)))\n",
    "    return query_indices[:query_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b613b78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 5/39 [==>...........................] - ETA: 3s - loss: 1.9438 - accuracy: 0.3607"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 135\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Main\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNum_Classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCRDHSI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVaC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTeC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mquery_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 19\u001b[0m, in \u001b[0;36mmain_pipeline\u001b[0;34m(WS, k, Num_Classes, CRDHSI, GT, Tr, TrC, Va, VaC, Te, TeC, num_iterations, query_percentage, epochs, batch_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m sample_counts \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_training_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m: Tr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_Train_class_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m: count_class_samples(TrC, Num_Classes),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     18\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVaC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m Tr_Time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# initial_flops = compute_flops(model)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ATL-MHSSMamba\n",
    "def main_pipeline(WS, k, Num_Classes, CRDHSI, GT, Tr, TrC, Va, VaC, Te, TeC, num_iterations, query_percentage, epochs, batch_size):  \n",
    "    model = SSMambaModel(out_channels=64, num_heads=4, state_dim=128, dropout=0.1)\n",
    "    _ = model(Tr[:batch_size])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    # Initialize a dictionary to store sample counts\n",
    "    sample_counts = {\n",
    "        \"initial_training_samples\": Tr.shape[0],\n",
    "        \"initial_Train_class_counts\": count_class_samples(TrC, Num_Classes),\n",
    "        \"initial_validation_samples\": Va.shape[0],\n",
    "        \"initial_Val_class_counts\": count_class_samples(VaC, Num_Classes),\n",
    "        \"Test_samples\": Te.shape[0],\n",
    "        \"class_Test_counts\": count_class_samples(TeC, Num_Classes),\n",
    "        \"iterations\": []\n",
    "    }\n",
    "\n",
    "    start = time.time()\n",
    "    history = model.fit(x=Tr, y=TrC, batch_size=batch_size, epochs=epochs, validation_data=(Va, VaC))\n",
    "    Tr_Time = time.time() - start\n",
    "\n",
    "    # initial_flops = compute_flops(model)\n",
    "    dummy = tf.zeros((1, WS, WS, k), dtype=tf.float32)  # 或用 tf.zeros_like(Tr[:1])\n",
    "    initial_flops = compute_flops(model, dummy, training=False, return_macs=False)\n",
    "\n",
    "     # Record initial counts\n",
    "    sample_counts[\"iterations\"].append({\n",
    "        \"iteration\": 1,\n",
    "        \"training_samples\": Tr.shape[0],\n",
    "        \"class_train_counts\": count_class_samples(TrC, Num_Classes),\n",
    "        \"validation_samples\": Va.shape[0],\n",
    "        \"class_Val_counts\": count_class_samples(VaC, Num_Classes), \n",
    "        \"Test_samples\": Te.shape[0],\n",
    "        \"class_Test_counts\": count_class_samples(TeC, Num_Classes)\n",
    "    })\n",
    "    \n",
    "    start = time.time()\n",
    "    Te_Pre = model.predict(Te)\n",
    "    end = time.time()\n",
    "    Te_Time = end - start\n",
    "    trainable_parameters = model.count_params()\n",
    "    classification,Confusion,OA,Per_Class,AA,Kappa = ClassificationReports(TeC, Te_Pre, target_names)\n",
    "    file_name = f\"{HSID}_{teRatio}_{k}_{WS}_{DLM}_Classification_Report.csv\"\n",
    "    CSV_file = CSVResults(file_name, classification, Confusion, trainable_parameters, \n",
    "                          initial_flops, Tr_Time, Te_Time, DL_Time, Kappa, OA, AA, Per_Class)\n",
    "    \n",
    "    # Ground Truths for inital Training\n",
    "    outputs = GT_Plot(CRDHSI, GT, model, WS, k)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(outputs, cmap='nipy_spectral')\n",
    "    plt.axis('off')\n",
    "    file_name = f\"{HSID}_{teRatio}_{k}_{WS}_{DLM}_Ground_Truths.png\"\n",
    "    plt.savefig(file_name, dpi=500, format='png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "     # Active Learning Iterations\n",
    "    for i in range(1, num_iterations+1):\n",
    "        print(f\"Active Learning Iteration {i}/{num_iterations}\")\n",
    "        # Query new samples from the pool using uncertainty sampling\n",
    "        query_size = int(query_percentage * Va.shape[0])\n",
    "        query_indices = hybrid_query_strategy(model, Va, query_size)\n",
    "        queried_X = Va[query_indices]\n",
    "        queried_y = VaC[query_indices]\n",
    "        \n",
    "        # Add queried samples back to the training set\n",
    "        Tr = np.concatenate([Tr, queried_X], axis=0)\n",
    "        TrC = np.concatenate([TrC, queried_y], axis=0)\n",
    "        # Remove queried samples from the pool\n",
    "        Va = np.delete(Va, query_indices, axis=0)\n",
    "        VaC = np.delete(VaC, query_indices, axis=0)\n",
    "        # Record counts after querying\n",
    "        sample_counts[\"iterations\"].append({\n",
    "            \"iteration\": i+1,\n",
    "            \"training_samples\": Tr.shape[0],\n",
    "            \"class_train_counts\": count_class_samples(TrC, Num_Classes),\n",
    "            \"validation_samples\": Va.shape[0],\n",
    "            \"class_Val_counts\": count_class_samples(VaC, Num_Classes)\n",
    "        })\n",
    "        # freeze feature learning layers and fine-tune classification layers\n",
    "        for layer in model.layers[:-3]:\n",
    "            layer.trainable = False\n",
    "        # Fine-tuning the model\n",
    "        fine_tune_start_time = time.time()\n",
    "        history = model.fit(x=Tr, y=TrC, batch_size=batch_size, epochs=epochs, validation_data=(Va, VaC))\n",
    "        fine_tune_time = time.time() - fine_tune_start_time\n",
    "        # Compute FLOPs for the Fine_tuned model\n",
    "        # Fine_tuned_flops = compute_flops(model)\n",
    "        dummy = tf.zeros((1, WS, WS, k), dtype=tf.float32)\n",
    "        Fine_tuned_flops = compute_flops(model, dummy, training=False, return_macs=False)\n",
    "\n",
    "        Finetuned_parameters = model.count_params()\n",
    "        ## Test Phase \n",
    "        start = time.time()\n",
    "        Te_Pre = model.predict(Te)\n",
    "        end = time.time()\n",
    "        Te_Time = end - start\n",
    "        ## Classification Report for Test Model\n",
    "        classification, Confusion, OA, Per_Class, AA, Kappa = ClassificationReports(TeC, Te_Pre, target_names)\n",
    "        file_name = f\"{i+1}_{HSID}_{trRatio}_{WS}_Classification_Report.csv\"\n",
    "        CSV_file = CSVResults(file_name, classification, Confusion, Finetuned_parameters, \n",
    "                          Fine_tuned_flops, fine_tune_time, Te_Time, DL_Time, Kappa, OA, AA, Per_Class)\n",
    "        # Ground Truths\n",
    "        outputs = GT_Plot(CRDHSI, GT, model, WS, k)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(outputs, cmap='nipy_spectral')\n",
    "        plt.axis('off')\n",
    "        file_name = f\"{i+1}_{HSID}_{trRatio}_{WS}_Ground_Truths.png\"\n",
    "        plt.savefig(file_name, dpi=500, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        # Save the model during the last iteration\n",
    "        if i == num_iterations:\n",
    "            model.save(f\"{HSID}_trained_ssmamba_model.tf\")\n",
    "            print(f\"Model saved at iteration {i} as 'final_model_iteration.tf'\")\n",
    "\n",
    "    # Save sample counts to a file\n",
    "    sample_counts_filename = f\"{HSID}_{trRatio}_{WS}_sample_counts.json\"\n",
    "    with open(sample_counts_filename, 'w') as f:\n",
    "        json.dump(sample_counts, f, indent=4)    \n",
    "    # Extract training and validation metrics\n",
    "    accuracy = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "        # Check if validation metrics exist\n",
    "    val_accuracy = history.history.get('val_accuracy', [])\n",
    "    val_loss = history.history.get('val_loss', [])\n",
    "    # Create a DataFrame\n",
    "    history_df = pd.DataFrame({\n",
    "        'Epoch': range(1, len(accuracy) + 1),\n",
    "        'Training Accuracy': accuracy,\n",
    "        'Training Loss': loss,\n",
    "        'Validation Accuracy': val_accuracy if val_accuracy else ['N/A'] * len(accuracy),\n",
    "        'Validation Loss': val_loss if val_loss else ['N/A'] * len(accuracy)\n",
    "    })\n",
    "    # Save to CSV\n",
    "    history_df.to_csv(f\"{HSID}_training_history.csv\", index=False)\n",
    "    return model\n",
    "# Main\n",
    "model = main_pipeline(WS, k, Num_Classes, CRDHSI, GT, Tr, TrC, Va, VaC, Te, TeC, num_iterations=5, \n",
    "                      query_percentage=0.02, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "530f2d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded old SSMamba from: PU_trained_ssmamba_model.tf\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 125ms/step - loss: 6.2770 - accuracy: 0.1498 - val_loss: 2.9505 - val_accuracy: 0.2864\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 3s 120ms/step - loss: 2.1151 - accuracy: 0.4487 - val_loss: 1.5991 - val_accuracy: 0.5592\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 3s 120ms/step - loss: 1.5546 - accuracy: 0.5766 - val_loss: 1.4072 - val_accuracy: 0.5993\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 3s 113ms/step - loss: 1.4294 - accuracy: 0.6025 - val_loss: 1.3370 - val_accuracy: 0.6226\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 3s 108ms/step - loss: 1.3718 - accuracy: 0.6258 - val_loss: 1.2976 - val_accuracy: 0.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 11:31:31.211209: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-04 11:31:31.211263: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-09-04 11:31:31.211382: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-09-04 11:31:31.211694: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-04 11:31:31.211724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-04 11:31:31.211736: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-04 11:31:31.211740: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-09-04 11:31:31.212048: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-04 11:31:31.212062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-09-04 11:31:31.212081: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-04 11:31:31.212091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9131 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "op: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "MatMul                   1.90m float_ops (100.00%, 61.82%)\n",
      "BatchMatMulV2            1.05m float_ops (38.18%, 34.04%)\n",
      "Softmax                  82.00k float_ops (4.15%, 2.66%)\n",
      "BiasAdd                  21.01k float_ops (1.48%, 0.68%)\n",
      "RealDiv                  16.38k float_ops (0.80%, 0.53%)\n",
      "Mul                      8.19k float_ops (0.27%, 0.27%)\n",
      "AddV2                      128 float_ops (0.00%, 0.00%)\n",
      "\n",
      "======================End of Report==========================\n",
      "235/235 [==============================] - 4s 15ms/step\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  Healthy grass       0.80      0.75      0.77       626\n",
      " Stressed grass       0.84      0.94      0.89       627\n",
      "Synthetic grass       0.89      0.86      0.87       348\n",
      "          Trees       0.69      0.87      0.77       622\n",
      "           Soil       0.74      0.99      0.85       621\n",
      "          Water       0.86      0.75      0.80       162\n",
      "    Residential       0.51      0.71      0.60       634\n",
      "     Commercial       0.47      0.36      0.40       622\n",
      "           Road       0.51      0.21      0.30       626\n",
      "        Highway       0.70      0.56      0.62       614\n",
      "        Railway       0.55      0.37      0.44       618\n",
      "  Parking Lot 1       0.47      0.69      0.56       617\n",
      "  Parking Lot 2       0.59      0.14      0.22       234\n",
      "   Tennis Court       0.65      0.96      0.77       214\n",
      "  Running Track       0.91      0.92      0.91       330\n",
      "\n",
      "       accuracy                           0.66      7515\n",
      "      macro avg       0.68      0.67      0.65      7515\n",
      "   weighted avg       0.66      0.66      0.64      7515\n",
      "\n",
      "[OK] Saved CSV: UH_0.1_8_Classification_Report.csv\n",
      "470/470 [==============================] - 7s 16ms/step\n",
      "[OK] Saved map: UH_0.1_8_Ground_Truths.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Across data classification\n",
    "## Load the Model\n",
    "from tensorflow.keras.models import load_model\n",
    "OLD_MODEL_PATH = \"PU_trained_ssmamba_model.tf\"\n",
    "customs = {\n",
    "    \"SpectralSpatialTokenGeneration\": SpectralSpatialTokenGeneration,\n",
    "    \"SpectralSpatialFeatureEnhancement\": SpectralSpatialFeatureEnhancement,\n",
    "    \"MultiHeadAttention\": MultiHeadAttention,       # 如果你仍用这个类名，则也提供\n",
    "    \"StateSpaceModel\": StateSpaceModel,\n",
    "    \"_SSMCell\": _SSMCell,\n",
    "    \"SSMambaModel\": SSMambaModel,\n",
    "}\n",
    "\n",
    "trained_model = load_model(\n",
    "    OLD_MODEL_PATH,   # 或 .keras\n",
    "    custom_objects=customs,\n",
    "    compile=False,\n",
    "    safe_mode=False\n",
    ")\n",
    "print(f\"[OK] Loaded old SSMamba from: {OLD_MODEL_PATH}\")\n",
    "# 新数据集\n",
    "HSID = \"UH\"\n",
    "HSI, GT, Num_Classes, target_names = LoadHSIData(HSID)\n",
    "RDHSI = DLMethod(DLM, HSI, NC=k)\n",
    "CRDHSI, CGT = ImageCubes(RDHSI, GT, WS=WS)\n",
    "Tr, Va, Te, TrC_idx, VaC_idx, TeC_idx = TrTeSplit(CRDHSI, CGT, 0.2, 0.8, 0.5)\n",
    "TrC = to_categorical(TrC_idx, num_classes=Num_Classes)\n",
    "VaC = to_categorical(VaC_idx, num_classes=Num_Classes)\n",
    "TeC = to_categorical(TeC_idx, num_classes=Num_Classes)\n",
    "\n",
    "# Retrain the model (freeze feature learning layers and fine-tune classification layer)\n",
    "# 1) 冻结骨干\n",
    "for sub in [trained_model.token_generation,\n",
    "            trained_model.multi_head_attention,\n",
    "            trained_model.feature_enhancement,\n",
    "            trained_model.state_space_model]:\n",
    "    sub.trainable = False\n",
    "\n",
    "# 2) 用新数据集的类别数，直接替换分类头\n",
    "trained_model.classifier = tf.keras.layers.Dense(Num_Classes, activation='softmax', name='classifier')\n",
    "\n",
    "# 3) 走一遍前向，构建新头\n",
    "_ = trained_model(tf.zeros((1, WS, WS, k), dtype=tf.float32))\n",
    "\n",
    "# 4) 编译 & 训练\n",
    "trained_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model= trained_model  # 直接用这个模型继续训练\n",
    "\n",
    "# # 新实例（类别数 = 新数据集）\n",
    "# new_mamba = SSMambaModel(out_channels=64, num_heads=4, state_dim=128, dropout=0.1)\n",
    "# new_mamba.set_num_classes(Num_Classes)\n",
    "# _ = new_mamba(tf.zeros((1, WS, WS, k), dtype=tf.float32))  # build\n",
    "\n",
    "# # 从旧模型把“骨干”权重拷到新模型（分类头保持新）\n",
    "# new_mamba.token_generation.set_weights(trained_model.token_generation.get_weights())\n",
    "# new_mamba.multi_head_attention.set_weights(trained_model.multi_head_attention.get_weights())\n",
    "# new_mamba.feature_enhancement.set_weights(trained_model.feature_enhancement.get_weights())\n",
    "# new_mamba.state_space_model.set_weights(trained_model.state_space_model.get_weights())\n",
    "\n",
    "# # 冻结骨干，编译、微调、评估、写 CSV/画图 —— 与方案 A 相同\n",
    "# for sub in [new_mamba.token_generation, new_mamba.multi_head_attention, new_mamba.feature_enhancement, new_mamba.state_space_model]:\n",
    "#     sub.trainable = False\n",
    "\n",
    "# new_mamba.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ---------- 6) 微调 ----------\n",
    "fine_tune_start_time = time.time()\n",
    "history = model.fit(Tr, TrC, batch_size=batch_size, epochs=epochs, validation_data=(Va, VaC))\n",
    "fine_tune_time = time.time() - fine_tune_start_time\n",
    "\n",
    "# ---------- 7) FLOPs / 参数量 ----------\n",
    "dummy = tf.zeros((1, WS, WS, k), dtype=tf.float32)\n",
    "Fine_tuned_flops = compute_flops(model, dummy, training=False, return_macs=False)  # FLOPs\n",
    "Finetuned_parameters = model.count_params()\n",
    "\n",
    "# ---------- 8) 测试评估 ----------\n",
    "start = time.time()\n",
    "Te_Pre = model.predict(Te)\n",
    "Te_Time = time.time() - start\n",
    "\n",
    "classification, Confusion, OA, Per_Class, AA, Kappa = ClassificationReports(TeC, Te_Pre, target_names)\n",
    "print(classification)\n",
    "\n",
    "# ---------- 9) 写 CSV（与你的 CSVResults 签名完全对齐） ----------\n",
    "# 若你没有 DL_Time，可用 0.0 占位\n",
    "DL_Time = 0.0\n",
    "file_name = f\"{HSID}_{trRatio}_{WS}_Classification_Report.csv\"\n",
    "_ = CSVResults(\n",
    "    file_name=file_name,\n",
    "    classification=classification,\n",
    "    confusion=Confusion,\n",
    "    Parameters=Finetuned_parameters,\n",
    "    Flops=Fine_tuned_flops,\n",
    "    Tr_Time=fine_tune_time,\n",
    "    Te_Time=Te_Time,\n",
    "    DL_Time=DL_Time,\n",
    "    kappa=Kappa,\n",
    "    oa=OA,\n",
    "    aa=AA,\n",
    "    each_acc=Per_Class\n",
    ")\n",
    "print(f\"[OK] Saved CSV: {file_name}\")\n",
    "\n",
    "# ---------- 10) 生成伪彩标注图 ----------\n",
    "Predicted = model.predict(CRDHSI)\n",
    "Predicted = np.argmax(Predicted, axis=1)\n",
    "height, width = np.shape(GT)\n",
    "outputs = np.zeros((height, width))\n",
    "cnt = 0\n",
    "for aa in range(height):\n",
    "    for bb in range(width):\n",
    "        tgt = int(GT[aa, bb])\n",
    "        if tgt == 0:\n",
    "            continue\n",
    "        outputs[aa][bb] = Predicted[cnt]\n",
    "        cnt += 1\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(outputs, cmap='nipy_spectral')\n",
    "plt.axis('off')\n",
    "png_name = f\"{HSID}_{trRatio}_{WS}_Ground_Truths.png\"\n",
    "plt.savefig(png_name, dpi=500, format='png', bbox_inches='tight', pad_inches=0)\n",
    "print(f\"[OK] Saved map: {png_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved history: SA_training_history.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- 11) 训练曲线保存 ----------\n",
    "acc = history.history.get('accuracy', [])\n",
    "loss = history.history.get('loss', [])\n",
    "val_acc = history.history.get('val_accuracy', [])\n",
    "val_loss = history.history.get('val_loss', [])\n",
    "history_df = pd.DataFrame({\n",
    "    'Epoch': list(range(1, len(acc) + 1)),\n",
    "    'Training Accuracy': acc,\n",
    "    'Training Loss': loss,\n",
    "    'Validation Accuracy': val_acc if val_acc else ['N/A'] * len(acc),\n",
    "    'Validation Loss': val_loss if val_loss else ['N/A'] * len(acc),\n",
    "})\n",
    "hist_csv = f\"{HSID}_training_history.csv\"\n",
    "history_df.to_csv(hist_csv, index=False)\n",
    "print(f\"[OK] Saved history: {hist_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
